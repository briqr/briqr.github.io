---
title: "Unifying Part Detection and Association for Recurrent Multi-Person Pose Estimation"
collection: publications
excerpt: 'This work introduces the novel task of human pose synthesis from text. In order to solve this task, we propose a model that is based on a conditional generative adversarial network. It is designed to generate 2D human poses conditioned on human-written text descriptions. The model is trained and evaluated using the COCO dataset, which consists of images capturing complex everyday scenes. We show through qualitative and quantitative results that the model is capable of synthesizing plausible poses matching the given text, indicating it is possible to generate poses that are consistent with the given semantic features, especially for actions with distinctive poses. We also show that the model outperforms a vanilla GAN.'
date: 2020-May-04
paperurl: 'https://arxiv.org/abs/2005.00340'
venue: ''
Authors: Y. Zhang, R. Briq, J. Tanke, J. Gall
image: 'adversarial_syn_approach.png'
---
